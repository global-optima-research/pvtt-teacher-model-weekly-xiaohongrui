# ç¯å¢ƒé…ç½®

```sh
conda create -n wan22 python=3.10 -y
conda activate wan22

# Ensure torch >= 2.4.0
# If the installation of `flash_attn` fails, try installing the other packages first and install `flash_attn` last
pip install -r requirements.txt

# If you want to use CosyVoice to synthesize speech for Speech-to-Video Generation, please install requirements_s2v.txt additionally
pip install -r requirements_s2v.txt
```

```sh
pip install torch>=2.4.0 torchvision>=0.19.0 torchaudio --index-url https://download.pytorch.org/whl/cu121
# sudo apt update && sudo apt install -y gcc g++ nvcc build-essential python3-dev
# # æ¨èæ–¹å¼ï¼šæŒ‡å®šç‰ˆæœ¬ + ç¦ç”¨æ„å»ºéš”ç¦»ï¼ˆä½¿ç”¨å½“å‰ç¯å¢ƒçš„ Torchï¼‰
# pip install flash-attn==2.8.3 --no-build-isolation
cat requirements.txt | grep -v -E '^torch|^torchvision|^torchaudio|^flash_attn' | xargs pip install
pip install peft easydict decord moviepy imageio librosa --no-cache-dir
pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
```

| Models              | Download Links                                                                                                                              | Description |
|--------------------|---------------------------------------------------------------------------------------------------------------------------------------------|-------------|
| T2V-A14B    | ğŸ¤— [Huggingface](https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B)    ğŸ¤– [ModelScope](https://modelscope.cn/models/Wan-AI/Wan2.2-T2V-A14B)    | Text-to-Video MoE model, supports 480P & 720P |
| I2V-A14B    | ğŸ¤— [Huggingface](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B)    ğŸ¤– [ModelScope](https://modelscope.cn/models/Wan-AI/Wan2.2-I2V-A14B)    | Image-to-Video MoE model, supports 480P & 720P |
| TI2V-5B     | ğŸ¤— [Huggingface](https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B)     ğŸ¤– [ModelScope](https://modelscope.cn/models/Wan-AI/Wan2.2-TI2V-5B)     | High-compression VAE, T2V+I2V, supports 720P |
| S2V-14B     | ğŸ¤— [Huggingface](https://huggingface.co/Wan-AI/Wan2.2-S2V-14B)     ğŸ¤– [ModelScope](https://modelscope.cn/models/Wan-AI/Wan2.2-S2V-14B)     | Speech-to-Video model, supports 480P & 720P |
| Animate-14B | ğŸ¤— [Huggingface](https://huggingface.co/Wan-AI/Wan2.2-Animate-14B) ğŸ¤– [ModelScope](https://www.modelscope.cn/models/Wan-AI/Wan2.2-Animate-14B)  | Character animation and replacement | |


```sh
huggingface-cli download Wan-AI/Wan2.2-T2V-A14B --local-dir ./Wan2.2-T2V-A14B

huggingface-cli download Wan-AI/Wan2.2-I2V-A14B --local-dir ./Wan2.2-I2V-A14B

huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir ./Wan2.2-TI2V-5B
```

# sbatchæ–‡ä»¶

```sh
#!/bin/bash
#SBATCH --job-name=wan_inference  # Create a short name for your job
#SBATCH --output=logs/wan_output_%j.log  # Log output file, saved in the logs directory (%j is the job ID)
#SBATCH --error=logs/wan_error_%j.log   # Error log file
#SBATCH --nodes=1                # Number of nodes
#SBATCH --gpus=1                 # Number of GPUs per node (only valid for large/normal partitions)
#SBATCH --time=01:00:00         # Total run time limit (HH:MM:SS)
#SBATCH --partition=normal  # Partition (large/normal/cpu) to submit to
#SBATCH --account=mscaisuperpod      # Required only for multiple projects

# Navigate to the project directory
cd /home/hxiaoap/Wan2.2
# Prepare log directory
mkdir -p logs

# Load environment
module purge                     # Clear inherited environment modules
module load Anaconda3/2023.09-0  # Load the required modules
module load cuda12.2/toolkit/12.2.2

# ç¯å¢ƒåœ¨ï¼š/home/hxiaoap/.conda/envs/wan22
ENV_PATH="/home/hxiaoap/.conda/envs/wan22"
# å¼ºåˆ¶å°†ç¯å¢ƒçš„ bin ç›®å½•æ’å…¥åˆ° PATH çš„æœ€å‰é¢,è¿™æ ·å½“è¾“å…¥ python æ—¶ï¼Œç³»ç»Ÿåªèƒ½çœ‹åˆ°ä½ ç¯å¢ƒé‡Œçš„é‚£ä¸ªï¼Œçœ‹ä¸åˆ°ç³»ç»Ÿçš„
export PATH="$ENV_PATH/bin:$PATH"
# ä¸ºäº†ä¿é™©ï¼Œå°†åº“è·¯å¾„ä¹ŸåŠ è¿›å»
export LD_LIBRARY_PATH="$ENV_PATH/lib:$LD_LIBRARY_PATH"
# éªŒè¯æ—¶åˆ»
echo "å½“å‰ Python è·¯å¾„: $(which python)"
echo "å½“å‰ Python ç‰ˆæœ¬: $(python --version)"

# 4. è‡ªåŠ¨ç†”æ–­æœºåˆ¶ï¼šå¦‚æœä¸æ˜¯ Python 3.10ï¼Œç›´æ¥æŠ¥é”™é€€å‡ºï¼Œä¸æ‰§è¡Œåé¢ä»£ç 
if [[ "$(python --version)" != *"3.10"* ]]; then
    echo "âŒ é”™è¯¯ï¼šç¯å¢ƒåˆ‡æ¢å¤±è´¥ï¼å½“å‰ä¾ç„¶æ˜¯ Python $(python --version)"
    echo "è¯·æ£€æŸ¥ ENV_PATH å˜é‡æ˜¯å¦æ­£ç¡®æŒ‡å‘äº†ä½ çš„ Conda ç¯å¢ƒç›®å½•ã€‚"
    exit 1
fi
echo "âœ… ç¯å¢ƒé”å®šæˆåŠŸï¼šPython 3.10"


# echo ""
# echo "=== å®‰è£…/æ£€æŸ¥ä¾èµ– ==="
# # å®‰è£… EasyDict (ä¿®å¤ ModuleNotFoundError)
# pip install easydict --no-cache-dir
# pip install peft decord moviepy imageio librosa --no-cache-dir

# # å®‰è£… Flash-Attention (ä½¿ç”¨é¢„ç¼–è¯‘åŒ…ï¼Œè·³è¿‡ç¼–è¯‘)
# echo "æ­£åœ¨å®‰è£… Flash-Attention..."
# pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.6.3/flash_attn-2.6.3+cu123torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
# å®‰è£…flash-attnï¼ˆæ¨è--no-build-isolationé¿å…ç¼–è¯‘ä¾èµ–é—®é¢˜ï¼‰
# pip install flash-attn==2.6.3 --no-build-isolation -i https://pypi.tuna.tsinghua.edu.cn/simple

echo ""
echo "=== Checking installed packages ==="
python - <<'PYCODE'
import torch, diffusers, transformers, accelerate
print(f"torch version        : {torch.__version__}")
print(f"diffusers version    : {diffusers.__version__}")
print(f"transformers version : {transformers.__version__}")
print(f"accelerate version   : {accelerate.__version__}")
PYCODE
echo "==================================="


# Execute inference command
# è®°å½•å¼€å§‹æ—¶é—´
START_TIME=$(date +"%Y-%m-%d %H:%M:%S")
echo -e "\n $START_TIME æ¨ç†å¼€å§‹..." >> logs/wan_output_${SLURM_JOB_ID}.log

python generate.py  \
  --task t2v-A14B \
  --size 1280*720 \
  --ckpt_dir ./Wan2.2-T2V-A14B \
  --offload_model True \
  --convert_model_dtype \
  --prompt "Two anthropomorphic cats in comfy boxing gear and bright gloves fight intensely on a spotlighted stage."

# è®°å½•ç»“æŸæ—¶é—´
END_TIME=$(date +"%Y-%m-%d %H:%M:%S")
echo "$END_TIME æ¨ç†ç»“æŸ" >> logs/wan_output_${SLURM_JOB_ID}.log

# è®¡ç®—è€—æ—¶ï¼ˆè½¬æ¢ä¸ºæ—¶é—´æˆ³è®¡ç®—å·®å€¼ï¼‰
START_TIMESTAMP=$(date -d "$START_TIME" +%s)
END_TIMESTAMP=$(date -d "$END_TIME" +%s)
DURATION=$((END_TIMESTAMP - START_TIMESTAMP))
HOURS=$((DURATION / 3600))
MINUTES=$(((DURATION % 3600) / 60))
SECONDS=$((DURATION % 60))
echo "æ¨ç†æ€»è€—æ—¶: ${HOURS}å°æ—¶${MINUTES}åˆ†é’Ÿ${SECONDS}ç§’" >> logs/wan_output_${SLURM_JOB_ID}.log


if [ $? -eq 0 ]; then
  # Output on success
  echo "Inference task completed."
else
  # Output on failure
  echo "Inference task failed! Check the error log: cat logs/wan_error_"$SLURM_JOB_ID".log"
fi
```

```sh
sed -i 's/\r$//' inference.sbatch
sbatch inference.sbatch
squeue -u hxiaoap
```