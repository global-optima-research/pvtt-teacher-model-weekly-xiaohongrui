# wan2.1 é¡¹ç›®ç»“æ„æ¦‚è§ˆ

```markdown
F:.
â”‚  .gitignore
â”‚  .style.yapf
â”‚  generate.py  # [â­å…¥å£æ–‡ä»¶] æ¨ç†è„šæœ¬çš„å…¥å£ã€‚é˜…è¯»å®ƒå¯ä»¥äº†è§£å¦‚ä½•åˆå§‹åŒ–Pipelineã€åŠ è½½æ¨¡å‹ä»¥åŠè°ƒç”¨ç”Ÿæˆå‡½æ•°ã€‚
â”‚  INSTALL.md
â”‚  LICENSE.txt
â”‚  Makefile
â”‚  pyproject.toml
â”‚  README.md
â”‚  requirements.txt
â”‚
â”œâ”€assets
â”‚      ... (é¡¹ç›®æ¼”ç¤ºå›¾ç‰‡ï¼Œéä»£ç ï¼Œè·³è¿‡)
â”‚
â”œâ”€examples
â”‚      ... (ç¤ºä¾‹è¾“å…¥å›¾ç‰‡ï¼Œç”¨äºè·‘æµ‹è¯•demoï¼Œè·³è¿‡)
â”‚
â”œâ”€gradio
â”‚      ... (Gradio WebUIçš„å¯åŠ¨è„šæœ¬ï¼Œé€»è¾‘è¾ƒç®€å•ï¼Œä¸»è¦æ˜¯è°ƒç”¨wanåŒ…é‡Œçš„åŠŸèƒ½ï¼Œå‚è€ƒä»·å€¼ä¸€èˆ¬)
â”‚
â”œâ”€tests
â”‚      ... (æµ‹è¯•è„šæœ¬ï¼Œè·³è¿‡)
â”‚
â””â”€wan  # [â­æ ¸å¿ƒåŒ…] æ‰€æœ‰çš„æ ¸å¿ƒé€»è¾‘éƒ½åœ¨è¿™é‡Œ
    â”‚  first_last_frame2video.py
    â”‚  image2video.py  # [â­æµç¨‹å‚è€ƒ] I2Vçš„æ¨ç†Pipelineã€‚æ‚¨åšVideo Editingä¸»è¦å‚è€ƒè¿™ä¸ªæ–‡ä»¶ï¼Œçœ‹å®ƒå¦‚ä½•å¤„ç†Imageè¾“å…¥å¹¶è½¬ä¸ºLatentä¼ ç»™DiTã€‚
    â”‚  text2video.py
    â”‚  vace.py
    â”‚  __init__.py
    â”‚
    â”œâ”€configs  # [ğŸ› ï¸é…ç½®ä¸­å¿ƒ]
    â”‚      shared_config.py
    â”‚      wan_i2v_14B.py  # [ğŸ› ï¸æ”¹é€ é‡ç‚¹] I2Væ¨¡å‹çš„é…ç½®æ–‡ä»¶ã€‚æ‚¨ä¿®æ”¹æ¨¡å‹è¾“å…¥é€šé“æ•°(in_channels)æ—¶ï¼Œéœ€è¦ä¿®æ”¹è¿™é‡Œçš„å‚æ•°ã€‚
    â”‚      wan_t2v_14B.py
    â”‚      wan_t2v_1_3B.py
    â”‚      __init__.py
    â”‚
    â”œâ”€distributed  # [åˆ†å¸ƒå¼è®­ç»ƒ]
    â”‚      fsdp.py  # Fully Sharded Data Parallel å°è£…ï¼Œå¤§è§„æ¨¡è®­ç»ƒæ—¶ç”¨ã€‚
    â”‚      xdit_context_parallel.py  # ä¸Šä¸‹æ–‡å¹¶è¡Œï¼Œé•¿è§†é¢‘ç”Ÿæˆ/è®­ç»ƒæ—¶å…³é”®ã€‚
    â”‚      __init__.py
    â”‚
    â”œâ”€modules  # [â­æ¨¡å‹æ¶æ„æ ¸å¿ƒ] è¿™é‡Œæ˜¯æ‚¨å·¥ä½œé‡æœ€å¤§çš„åœ°æ–¹
    â”‚      attention.py  # [ğŸ› ï¸LoRAé‡ç‚¹] å®šä¹‰äº†Attentionæœºåˆ¶ã€‚è¦åœ¨ç‰¹å®šå±‚æ³¨å…¥LoRAï¼Œé€šå¸¸æ˜¯åœ¨è¿™é‡Œæˆ–è€…model.pyä¸­å®šä½Linearå±‚ã€‚
    â”‚      clip.py       # æ–‡æœ¬ç¼–ç å™¨ç›¸å…³ã€‚
    â”‚      model.py      # [â­æ ¸å¿ƒå¿…è¯»][ğŸ› ï¸æ”¹é€ é‡ç‚¹] DiT (Diffusion Transformer) çš„ä¸»å¹²ç½‘ç»œå®šä¹‰ï¼
    â”‚                    # 1. å¯»æ‰¾ `patch_embedding` æˆ–è¾“å…¥å±‚ï¼šæ‚¨éœ€è¦åœ¨è¿™é‡Œä¿®æ”¹ä»£ç ï¼Œä½¿å…¶èƒ½æ¥å—é¢å¤–çš„Ref Image Latenté€šé“ã€‚
    â”‚                    # 2. å¯»æ‰¾ `blocks`ï¼šç†è§£Transformer Blockçš„å †å æ–¹å¼ã€‚
    â”‚      t5.py         # æ–‡æœ¬ç¼–ç å™¨ç›¸å…³ã€‚
    â”‚      tokenizers.py
    â”‚      vace_model.py # è§†é¢‘å‹ç¼©æ¨¡å‹çš„å…·ä½“å®ç°ã€‚
    â”‚      vae.py        # [â­å¿…è¯»] VAEç›¸å…³ä»£ç ã€‚æ‚¨éœ€è¦äº†è§£å›¾åƒ/è§†é¢‘å¦‚ä½•è¢«å‹ç¼©æˆLatentï¼ˆå½¢çŠ¶ã€ç»´åº¦ï¼‰ï¼Œæ‰èƒ½å¯¹é½Ref Imageçš„è¾“å…¥ç»´åº¦ã€‚
    â”‚      xlm_roberta.py
    â”‚      __init__.py
    â”‚
    â””â”€utils
            fm_solvers.py        # Flow Matching é‡‡æ ·å™¨ï¼ˆç±»ä¼¼Diffusionçš„Schedulerï¼‰ã€‚
            fm_solvers_unipc.py  # UniPC é‡‡æ ·å™¨ã€‚
            prompt_extend.py     # Prompt å¢å¼º/æ‰©å±•å·¥å…·ã€‚
            qwen_vl_utils.py     # å¤šæ¨¡æ€å¤§æ¨¡å‹å·¥å…·ï¼ˆå¯èƒ½ç”¨äºPromptç†è§£ï¼‰ã€‚
            utils.py             # é€šç”¨å·¥å…·å‡½æ•°ã€‚
            vace_processor.py    # VACEçš„æ•°æ®é¢„å¤„ç†ã€‚
            __init__.py
```

# æ€»è§ˆï¼šWan2.1 çš„ç”Ÿæˆé“¾è·¯ä¸â€œå¼ é‡è¯­ä¹‰â€

Wan åŸºæœ¬éµå¾ª â€œVAE latent diffusion + DiT + æ–‡æœ¬ç¼–ç å™¨â€ èŒƒå¼ï¼ˆè®ºæ–‡å›¾9ï¼Œç¬¬13é¡µï¼‰ï¼š

1) **åƒç´ è§†é¢‘** \(V\in \mathbb{R}^{(1+T)\times H\times W\times 3}\)  
2) **Wan-VAE Encoder** å‹ç¼©å¾—åˆ° latent  
   \[
   x\in \mathbb{R}^{(1+T/4)\times H/8\times W/8\times C},\quad C=16
   \]
   ï¼ˆè®ºæ–‡4.1.1ï¼Œç¬¬10é¡µï¼›å‹ç¼©ç‡ 4Ã—8Ã—8ï¼‰
3) **æ‰©æ•£/Flow Matching è¿‡ç¨‹**åœ¨ latent ä¸Šè¿›è¡Œï¼šä»å™ªå£°é€æ­¥ç§¯åˆ†å›æ•°æ®
4) **DiTï¼ˆWanModelï¼‰**ï¼šè¾“å…¥å½“å‰ \(x_t\)ï¼ˆlatentï¼‰+ æ¡ä»¶ï¼ˆæ–‡æœ¬/å›¾åƒç­‰ï¼‰+ timestepï¼Œè¾“å‡º **velocity/flow** é¢„æµ‹ï¼ˆæˆ–ç» scheduler è½¬æˆ \(x_0\) / \(\epsilon\) æ‰€éœ€å½¢å¼ï¼‰
5) **Wan-VAE Decoder** å°†æœ€ç»ˆ latent è§£ç å›åƒç´ è§†é¢‘ã€‚

> ä½ åœ¨ä»£ç é‡Œçœ‹åˆ°çš„å…³é”®äº‹å®ï¼š**Wan2.1 è®­ç»ƒ/é‡‡æ ·çš„ prediction_type æ˜¯ flow_prediction**ï¼ˆè®ºæ–‡å…¬å¼(1)(2)(3)ï¼Œç¬¬14-15é¡µï¼›ä»£ç  `fm_solvers.py: convert_model_output`ï¼‰ã€‚

# Wan-VAEï¼š3D Causal VAE æ¶æ„ï¼ˆè®ºæ–‡4.1ï¼›æºç  `vae.py`ï¼‰

## ä¸ºä»€ä¹ˆéœ€è¦â€œ3D + Causalâ€çš„è§†é¢‘ VAEï¼Ÿ

è®ºæ–‡4.1å¼€å¤´ï¼ˆç¬¬10é¡µï¼‰åˆ—äº†ä¸‰ç±»æŒ‘æˆ˜ï¼š
- **è§†é¢‘æ˜¯æ—¶ç©ºæ•°æ®**ï¼šä¸ä»…è¦å‹ç©ºé—´ï¼Œè¿˜è¦å‹æ—¶é—´ï¼ˆå¦åˆ™ token å¤ªé•¿ï¼ŒDiT attention äºŒæ¬¡æ–¹çˆ†ç‚¸ï¼‰ã€‚
- **é«˜ç»´å¯¼è‡´è®­ç»ƒ/æ¨ç†æˆæœ¬æé«˜**ï¼šéœ€è¦å¼ºå‹ç¼©ï¼ˆWan é‡‡ç”¨ 4Ã—8Ã—8ï¼‰ã€‚
- **æ—¶é—´å› æœæ€§ï¼ˆtemporal causalityï¼‰**ï¼šæœªæ¥å¸§ä¸èƒ½æ³„éœ²åˆ°è¿‡å»å¸§ï¼Œå°¤å…¶åœ¨æµå¼/é•¿è§†é¢‘ç”Ÿæˆæ—¶é‡è¦ã€‚

è¿™ç›´æ¥å¯¹åº”æºç é‡Œçš„ä¸¤ä¸ªæ ¸å¿ƒè®¾è®¡ï¼š
- **3Då·ç§¯**ï¼ˆConv3dï¼‰åŒæ—¶å¤„ç† \((T,H,W)\)
- **CausalConv3d + Feature Cache** ä¿è¯åªç”¨â€œè¿‡å»å¸§ä¸Šä¸‹æ–‡â€ã€‚

## VAE çš„å‹ç¼©æ¯”ä¸â€œ1+Tâ€æ—¶é—´æ ¼å¼ï¼ˆè®ºæ–‡å›¾5ï¼Œç¬¬10é¡µï¼‰

è®ºæ–‡æ˜ç¡®å†™ï¼šè¾“å…¥è§†é¢‘æ˜¯ **\([1+T, H, W, 3]\)**ï¼Œè¾“å‡º latent æ˜¯ **\([1+T/4, H/8, W/8, C]\)**ã€‚

è¿™ä»¶äº‹åœ¨æºç é‡Œä½“ç°ï¼š
- `image2video.py` è¦æ±‚ `frame_num` æ˜¯ **4n+1**ï¼Œå¹¶ä½¿ç”¨ `(F-1)//4+1` æ¥åˆ›å»ºå™ªå£°çš„æ—¶é—´é•¿åº¦ï¼ˆT_latï¼‰ã€‚
- `vae.py` é‡Œ `WanVAE_.encode()` æ˜ç¡®æŠŠè¾“å…¥æŒ‰æ—¶é—´åˆ‡å—ä¸ºï¼š**1å¸§ã€4å¸§ã€4å¸§â€¦**ï¼ˆæ³¨é‡Šé‡Œä¹Ÿå†™äº†ï¼š`## å¯¹encodeè¾“å…¥çš„xï¼ŒæŒ‰æ—¶é—´æ‹†åˆ†ä¸º1ã€4ã€4ã€4....`ï¼‰

**ç›´è§‰ç†è§£**ï¼š  
- ç¬¬0å¸§å•ç‹¬ä¿ç•™ï¼ˆå¯¹é½ image æ•°æ®/æ›´åƒ MagViT-v2 çš„ç­–ç•¥ï¼Œè®ºæ–‡4.1.1æåˆ° first frame only spatially compressedï¼Œè·Ÿä»£ç ç­–ç•¥ä¸€è‡´ï¼‰
- åç»­æ¯ 4 å¸§å‹æˆ 1 ä¸ª latent timestepï¼ˆæ—¶é—´å‹ç¼©Ã—4ï¼‰ã€‚

## 3D CNNï¼ˆConv3Dï¼‰åˆ°åº•åœ¨åšä»€ä¹ˆï¼Ÿ

**2D å·ç§¯å¯¹å›¾åƒåš**ï¼š
- è¾“å…¥ï¼š\([B,C,H,W]\)
- kernelï¼š\([C_{out},C_{in},k_h,k_w]\)
- è¾“å‡ºï¼š\([B,C_{out},H',W']\)


**3D å·ç§¯æŠŠâ€œæ—¶é—´â€ä¹Ÿå½“æˆå¯å·ç§¯ç»´åº¦**ï¼š
- è¾“å…¥ï¼š\([B,C,T,H,W]\)
- kernelï¼š\([C_{out},C_{in},k_t,k_h,k_w]\)
- è¾“å‡ºï¼š\([B,C_{out},T',H',W']\)

ä½ å¯ä»¥æŠŠå®ƒå½“æˆï¼šåœ¨æ¯ä¸ªè¾“å‡ºä½ç½® \((t,h,w)\)ï¼Œä¼šèšåˆä¸€ä¸ª **å±€éƒ¨æ—¶ç©ºå—** \([t-k_t/2:t+k_t/2,\,h-k_h/2:h+k_h/2,\,w-k_w/2:w+k_w/2]\) çš„ä¿¡æ¯ã€‚

**åœ¨è§†é¢‘ VAE çš„æ„ä¹‰**ï¼š
- Encoderï¼šç”¨ 3D å·ç§¯åœ¨å‹ç¼©æ—¶åŒæ—¶â€œç†è§£è¿åŠ¨/å˜åŒ–â€
- Decoderï¼šç”¨ 3D å·ç§¯åœ¨æ¢å¤æ—¶ä¿è¯æ—¶é—´è¿ç»­æ€§ï¼ˆæ›´åƒâ€œè§†é¢‘è§£ç å™¨â€è€Œä¸æ˜¯é€å¸§å›¾åƒè§£ç å™¨ï¼‰ã€‚

## CausalConv3dï¼šå¦‚ä½•ä¿è¯â€œä¸çœ‹æœªæ¥â€ï¼ˆæºç  `CausalConv3d`ï¼‰

`CausalConv3d` çš„å…³é”®æ˜¯ **æ—¶é—´ç»´åªåœ¨å·¦ä¾§ padding**ï¼Œå³ä¾§ä¸ paddingï¼š

- æ­£å¸¸ 3D å·ç§¯ padding=(p_t,p_h,p_w) ä¼šè®©è¾“å‡º t ä½ç½®èƒ½çœ‹åˆ° \(t\pm p_t\)
- causal åšæ³•ï¼šåª pad â€œè¿‡å»â€ï¼št_left = 2*p_t, t_right=0  
  è¿™æ ·è¾“å‡º at time=t åªä¾èµ– â‰¤t çš„è¾“å…¥å¸§ï¼ˆå†åŠ  cache æ—¶ä¹Ÿåªæ‹¼è¿‡å»å¸§ï¼‰ã€‚

æºç å®ç°è¦ç‚¹ï¼š
- æŠŠ Conv3d è‡ªå¸¦ padding ç½®0ï¼Œè‡ªå·±ç”¨ `F.pad(x, padding)` å®ç°
- `_padding` æ„é€ ä¸º `(w_left,w_right,h_left,h_right,t_left,t_right)`ï¼Œå…¶ä¸­ `t_right=0`
- æ”¯æŒ `cache_x`ï¼šæŠŠä¸Šä¸€ä¸ª chunk çš„å°¾éƒ¨å¸§ `torch.cat([cache_x,x], dim=2)` æ‹¼åœ¨å‰é¢ï¼Œç„¶åå‡å°‘éœ€è¦ pad çš„å¸§æ•°ã€‚

## Feature Cache Mechanismï¼šè®¾è®¡ç»†èŠ‚ä¸å·¥ä½œæµç¨‹ï¼ˆè®ºæ–‡4.1.3 + å›¾6ï¼›æºç  `vae.py`ï¼‰

è®ºæ–‡4.1.3ï¼ˆç¬¬11é¡µï¼‰è§£é‡Šäº† cache çš„åŠ¨æœºï¼š**æ”¯æŒä»»æ„é•¿è§†é¢‘çš„ç¼–ç /è§£ç ï¼Œé¿å…ä¸€æ¬¡æ€§æŠŠæ‰€æœ‰å¸§å¡è¿›æ˜¾å­˜**ã€‚åšæ³•æ˜¯ chunk-wiseï¼š
- è¾“å…¥è§†é¢‘æŒ‰æ—¶é—´åˆ‡æˆ \(1 + T/4\) ä¸ª chunkï¼ˆä¸ latent æ—¶é—´é•¿åº¦ä¸€è‡´ï¼‰
- æ¯ä¸ª chunk æœ€å¤šå¤„ç† 4 å¸§ï¼ˆç¬¬ä¸€ä¸ª chunk æ˜¯1å¸§ï¼‰
- ä¸ºäº† chunk è¾¹ç•Œè¿ç»­æ€§ï¼Œéœ€è¦ç¼“å­˜å‰ä¸€ chunk çš„æœ«å°¾ç‰¹å¾å¸§ä¾›ä¸‹ä¸€ chunk ä½¿ç”¨ï¼ˆå›¾6a/6bï¼‰

æºç å±‚é¢è¿™å¥—æœºåˆ¶çš„å®ç°â€œéå¸¸å·¥ç¨‹åŒ–â€ï¼š
- `WanVAE_.clear_cache()`ï¼šå…ˆç»Ÿè®¡ encoder/decoder é‡Œæœ‰å¤šå°‘ä¸ª `CausalConv3d`ï¼Œä¸ºæ¯ä¸ª conv å‡†å¤‡ä¸€ä¸ª cache æ§½ä½ï¼ˆlistï¼‰
- æ¯æ¬¡è¿›å…¥ä¸€ä¸ªå¸¦ cache çš„ convï¼šä» `feat_cache[idx]` å–å†å²å¸§ä½œä¸º `cache_x`ï¼›å·ç§¯åæŠŠå½“å‰ chunk çš„æœ€å `CACHE_T=2` å¸§å­˜å›å»ï¼›`feat_idx[0] += 1` æŒ‡å‘ä¸‹ä¸€ä¸ª conv çš„ cache æ§½ä½
- `CACHE_T=2` çš„åŸå› ï¼šå¤§å¤šæ•°æ—¶é—´ kernel_size=3ï¼ˆè®ºæ–‡ä¹Ÿè¯´ kernel=3 éœ€è¦ç»´æŠ¤2å¸§å†å²ï¼‰ï¼Œæ‰€ä»¥ç¼“å­˜2å¸§è¶³å¤Ÿä¿è¯è¾¹ç•Œå¤„å·ç§¯ç­‰ä»·äºæ•´æ®µå·ç§¯ã€‚

### å›¾6aï¼ˆè®ºæ–‡ç¬¬11é¡µï¼‰çš„å«ä¹‰å¯¹ç…§æºç 
â€œé»˜è®¤ settingï¼šå·ç§¯ä¸æ”¹å˜å¸§æ•°â€ï¼š
- kernel=3 => éœ€è¦ 2 å¸§å†å²
- chunk0 å¼€å§‹æ²¡æœ‰å†å² => ç”¨ 2 å¸§ zero padding åˆå§‹åŒ–
- chunk1 å¼€å§‹ï¼šç”¨ chunk0 çš„æœ€å2å¸§ä½œä¸º cache padding

è¿™ä¸æºç é‡Œï¼š
- åˆæ¬¡ cache æ˜¯ None æ—¶ï¼Œç”¨å ä½ç­–ç•¥ï¼ˆæœ‰äº›æ¨¡å—ç”¨ `'Rep'` æ ‡è®°ï¼‰æˆ–è€…æ‹¼é›¶å¸§
- æ­£å¸¸æƒ…å†µç¼“å­˜ `x[:, :, -CACHE_T:, :, :]`

### å›¾6bï¼ˆè®ºæ–‡ç¬¬11é¡µï¼‰çš„å«ä¹‰ï¼šæ—¶é—´ä¸‹é‡‡æ · stride=2 æ—¶çš„ cache

å½“ temporal downsampleï¼ˆ`downsample3d`ï¼‰å‡ºç°ï¼š
- stride=2 ä¼šè®©è¾“å‡ºå¸§æ•°å‡å°‘
- cache ç®¡ç†ä¸åŒï¼šè®ºæ–‡è¯´éœ€è¦ â€œsingle-frame cache padding for non-initial chunksâ€
æºç  `Resample(mode='downsample3d')` é‡Œç¡®å®æ˜¯ç¼“å­˜ `-1:` è¿™ 1 å¸§ï¼Œå¹¶åœ¨ä¸‹ä¸€ chunk å‰æ‹¼ä¸Šä¸Šä¸€chunkæœ€å1å¸§å† time_convã€‚


## VAE çš„ Encoder/Decoder ç»“æ„

`WanVAE_` ç»“æ„ï¼ˆ`vae.py`ï¼‰ï¼š

- Encoder3d:
  - `conv1: CausalConv3d(3 -> base_dim)`
  - å¤šå±‚ ResidualBlockï¼ˆæ¯ä¸ªå«ä¸¤ä¸ª CausalConv3dï¼‰
  - è‹¥å¹² Resample ä¸‹é‡‡æ ·ï¼ˆdownsample2d or downsample3dï¼‰
  - middle: Res + Attn + Resï¼ˆAttentionBlock æ˜¯â€œæ¯å¸§ç©ºé—´æ³¨æ„åŠ›â€ï¼‰
  - head: è¾“å‡ºåˆ° `z_dim*2`ï¼ˆmu/log_varï¼‰
  - `conv1` å† chunk(2) å¾— mu/log_varï¼ˆæœ€å encode åªè¿”å›æ ‡å‡†åŒ–åçš„ muï¼‰

- Decoder3d:
  - `conv1(z -> feat)`
  - middle: Res + Attn + Res
  - Resample ä¸Šé‡‡æ ·ï¼ˆupsample2d or upsample3dï¼Œupsample3d å¸¦ time_conv åšæ—¶é—´ä¸Šé‡‡æ ·ï¼‰
  - head: è¾“å‡º 3 é€šé“ RGB

**ç‰¹åˆ«ç‚¹**ï¼šè®ºæ–‡4.1.1æåˆ°æŠŠ GroupNorm æ¢æˆ RMSNorm ä»¥ä¿æŒ temporal causalityï¼Œå¹¶ä½¿ cache å¯ç”¨ï¼›æºç ç¡®å®æ˜¯ RMS_norm / WanRMSNorm é£æ ¼ï¼Œä¸ç”¨ GroupNormã€‚

# Wan DiTï¼ˆDiffusion Transformerï¼‰æ¶æ„ï¼ˆè®ºæ–‡4.2.1ï¼›æºç  `model.py`ï¼‰

## Patchifyï¼šæŠŠè§†é¢‘ latent å˜æˆ token åºåˆ—ï¼ˆè®ºæ–‡4.2.1ï¼Œç¬¬14é¡µï¼‰

è®ºæ–‡è¯´ patchify ç”¨ 3D conv kernel=(1,2,2)ï¼Œflattenæˆ \((B,L,D)\)ï¼Œå…¶ä¸­ï¼š
\[
L=(1+T/4)\times H/16\times W/16
\]
æ³¨æ„è¿™é‡Œçš„ \(H/16, W/16\) æ¥è‡ªï¼š
- latent æœ¬èº«æ˜¯ H/8, W/8ï¼ˆVAEå‹ç¼©ï¼‰
- patch_size ç©ºé—´æ˜¯ 2Ã—2ï¼Œå†å‹ä¸€æ¬¡ => H/16, W/16

æºç  `WanModel.patch_embedding = nn.Conv3d(in_dim, dim, kernel_size=patch_size, stride=patch_size)`ï¼Œé»˜è®¤ patch_size=(1,2,2) ä¸è®ºæ–‡ä¸€è‡´ã€‚

***

**ç»´åº¦è·Ÿè¸ªï¼ˆä»¥å•æ ·æœ¬ä¸ºä¾‹ï¼‰**
å‡è®¾ latentï¼ˆæ‰©æ•£ç©ºé—´ï¼‰è¾“å…¥æ˜¯ï¼š
- \(x\): `[C_in=16, T_lat, H_lat, W_lat]`
- ä¾‹å¦‚ 720pã€81å¸§ï¼ˆå¸¸è§è®¾ç½®ï¼‰ï¼š
  - åƒç´ ï¼šF=81, H=720, W=1280
  - latentï¼šT_lat = (81-1)//4+1 = 21  
    H_lat=720/8=90, W_lat=1280/8=160
  - patchify åç½‘æ ¼ï¼šFp=21/1=21, Hp=90/2=45, Wp=160/2=80
  - token æ•°ï¼šL=21*45*80=75,600

è¿™æ˜¯ä¸ºä»€ä¹ˆè§†é¢‘æ¨¡å‹ attention å·¨è´µï¼šL è½»æ¾åˆ° 10^5 çº§ã€‚

æºç å¯¹åº”ï¼š
- `patch_embedding(u.unsqueeze(0))` => `[1, dim, Fp, Hp, Wp]`
- `flatten(2).transpose(1,2)` => `[1, L, dim]`
- batch é‡Œæ¯ä¸ªæ ·æœ¬ pad åˆ° `seq_len` å¹¶ stack => `[B, seq_len, dim]`


## Transformer Blockï¼šSelf-Attn + Cross-Attn + FFNï¼ˆè®ºæ–‡å›¾10ï¼Œç¬¬14é¡µï¼‰

è®ºæ–‡å›¾10æ˜¯æ ‡å‡†ç»“æ„ï¼šLN -> SelfAttn -> LN -> CrossAttn -> LN -> FFNã€‚

æºç  `WanAttentionBlock`ï¼š
- `self_attn`ï¼š`WanSelfAttention`ï¼ˆfull spatio-temporal attentionï¼‰
- `cross_attn`ï¼št2v æˆ– i2v cross-attnï¼ˆæ–‡æœ¬/å›¾åƒæ¡ä»¶ï¼‰
- `ffn`ï¼šLinear-GELU-Linear
- é‡è¦ï¼šç”¨äº† â€œæ—¶é—´è°ƒåˆ¶å‚æ•° e (6ä»½)â€ çš„ AdaLN/FiLM-like ç»“æ„ï¼ˆè®ºæ–‡4.2.1è¯´ time MLP è¾“å‡º6ä¸ª modulation å‚æ•°ï¼Œå¹¶ä¸” MLP å…±äº«ï¼Œblocké‡Œåªå­¦ biasï¼›æºç å°±æ˜¯ `time_projection` å…±äº« + `block.modulation` å¯å­¦ä¹ åç½®ï¼‰ã€‚

---

## æ³¨æ„åŠ›æœºåˆ¶ï¼šWan æ˜¯å¦åŒºåˆ† Spatial / Temporal Attentionï¼Ÿ

ä½ æçš„å…³é”®é—®é¢˜ï¼š**Wan æ²¡æœ‰æŠŠç©ºé—´æ³¨æ„åŠ›å’Œæ—¶é—´æ³¨æ„åŠ›æ‹†å¼€ï¼Œè€Œæ˜¯ç›´æ¥åš full spatio-temporal self-attention**ã€‚ç»“è®ºæ˜¯ï¼šåœ¨ DiT ä¸»å¹²é‡Œï¼Œç¡®å®å¦‚æ­¤ã€‚

è¯æ®æ¥è‡ªè®ºæ–‡ä¸æºç ä¸¤ç«¯ï¼š

### è®ºæ–‡ä¾§ï¼ˆ4.2.1 & 1 Introductionï¼‰
è®ºæ–‡åœ¨å¼•è¨€æåˆ° â€œfull spatio-temporal attention mechanism is incorporatedâ€ï¼ˆç¬¬3é¡µé™„è¿‘ï¼‰ã€‚4.2.1 è®¨è®ºçš„æ˜¯å¯¹ flatten åçš„åºåˆ—åš self-attnï¼Œæ²¡æœ‰æ separableã€‚

### æºç ä¾§ï¼ˆ`WanSelfAttention` + 3D RoPEï¼‰
- è¾“å…¥ token åºåˆ—æ¥è‡ª **FpÃ—HpÃ—Wp çš„ 3D ç½‘æ ¼**ï¼ˆgrid_sizes=(F,H,W) patchç½‘æ ¼ï¼‰
- `rope_apply()` æ˜ç¡®æŒ‰ (F,H,W) åˆ†é…ä¸åŒç»´åº¦çš„ RoPE é¢‘ç‡ï¼Œå¹¶å¯¹ **q/k åœ¨ token ç»´åº¦æ•´ä½“æ—‹è½¬**
- `flash_attention(q,k,v,k_lens=seq_lens, window_size=...)` æ˜¯å¯¹æ•´ä¸ªåºåˆ—åš attentionï¼ˆä¸æ˜¯å…ˆç©ºé—´å†æ—¶é—´ï¼‰

å› æ­¤ï¼š**Wan çš„ DiT self-attn æ˜¯â€œæ—¶ç©ºtokenæ··åˆâ€çš„å…¨æ³¨æ„åŠ›**ï¼Œä¸æ˜¯ factorized çš„ (spatial attn + temporal attn)ã€‚

> ä½†è¦æ³¨æ„ï¼šVAE é‡Œ `AttentionBlock` æ˜¯â€œé€å¸§ç©ºé—´æ³¨æ„åŠ›â€ï¼ˆæŠŠ (B,T) åˆå¹¶æˆ batchï¼Œå¯¹ H*W åš attentionï¼‰ï¼Œé‚£æ˜¯ VAE çš„å†…éƒ¨è®¾è®¡ï¼Œä¸æ˜¯ DiT ä¸»å¹²ã€‚

## Cross-Attentionï¼šæ–‡æœ¬/å›¾åƒæ¡ä»¶å¦‚ä½•æ³¨å…¥ï¼Ÿ
æºç  `WAN_CROSSATTENTION_CLASSES`ï¼š
- `WanT2VCrossAttention`: qæ¥è‡ªè§†é¢‘tokenï¼Œk/væ¥è‡ªæ–‡æœ¬tokenï¼ˆumT5 512 tokensï¼‰
- `WanI2VCrossAttention`: context = [CLIPå›¾åƒtoken ; T5æ–‡æœ¬token]
  - å…ˆæ‹†å¼€å›¾åƒ token ä¸æ–‡æœ¬ token
  - å¯¹åŒä¸€ query åšä¸¤æ¬¡æ³¨æ„åŠ›ï¼šä¸€æ¬¡å¯¹å›¾åƒk/vï¼Œä¸€æ¬¡å¯¹æ–‡æœ¬k/vï¼Œç„¶åç›¸åŠ  `x = x + img_x`

è¿™å¯¹ä½ åç»­åš video editing / ref image é€šé“éå¸¸é‡è¦ï¼š
- ref image æœ€è‡ªç„¶çš„åšæ³•ä¹‹ä¸€å°±æ˜¯**ä½œä¸ºé¢å¤–çš„ context tokens**å¹¶æ‰©å±•è¿™é‡Œçš„æ‹†åˆ†ä¸èåˆç­–ç•¥ï¼ˆä¾‹å¦‚ ref tokens ç‹¬ç«‹ä¸€æ”¯ cross-attnï¼Œæˆ–ç”¨ gate/alpha èåˆï¼Œè€Œä¸æ˜¯ç®€å•åŠ å’Œï¼‰ã€‚

---

# Flow Matching / Rectified Flow è®­ç»ƒä¸é‡‡æ ·ï¼ˆè®ºæ–‡4.2.2ï¼›æºç  `fm_solvers.py`ï¼‰

## è®­ç»ƒç›®æ ‡ï¼šæ¨¡å‹é¢„æµ‹ velocityï¼ˆflowï¼‰
è®ºæ–‡å…¬å¼ï¼ˆç¬¬14é¡µï¼‰ï¼š

- é‡‡æ ·å™ªå£° \(x_0\sim \mathcal{N}(0,I)\)  
- æ•°æ® latent ä¸º \(x_1\)  
- æ—¶é—´ \(t\in[0,1]\)
- ä¸­é—´ç‚¹ï¼š
  \[
  x_t = t x_1 + (1-t) x_0
  \]
- çœŸå€¼é€Ÿåº¦ï¼š
  \[
  v_t = \frac{d x_t}{dt} = x_1 - x_0
  \]
- è®­ç»ƒï¼šæœ€å°åŒ– \(\|u(x_t, ctxt, t) - v_t\|_2^2\)

æºç å¯¹åº”å…³ç³»ï¼š
- `FlowDPMSolverMultistepScheduler.convert_model_output()` å‡è®¾ `prediction_type == "flow_prediction"`
- å¯¹ dpmsolver++ï¼šç”¨
  \[
  x0\_pred = x - \sigma_t \cdot v
  \]
  è¿™é‡Œ sample=xï¼ˆå½“å‰çŠ¶æ€ï¼‰ï¼Œmodel_output=vï¼ˆé€Ÿåº¦/flowï¼‰

è¿™è¯´æ˜ï¼š**WanModel è¾“å‡ºçš„â€œnoise_predâ€åœ¨ä»£ç é‡Œå‘½åä¸º noise_predï¼Œä½†è¯­ä¹‰æ›´æ¥è¿‘ flow/velocity**ï¼ˆå˜é‡åæ²¿ç”¨äº†æ‰©æ•£æ¨¡å‹ä¹ æƒ¯ï¼Œä½†å®é™…æ˜¯ flow matching çš„ vï¼‰ã€‚

---

## é‡‡æ ·ï¼šDPM-Solver++ åœ¨â€œflowå‚æ•°åŒ–â€ä¸‹æ€ä¹ˆæ›´æ–°ï¼Ÿ
æ¨ç†å¾ªç¯ï¼ˆä½ çœ‹è¿‡çš„ `image2video.py`ï¼‰æ ¸å¿ƒæ˜¯ï¼š

1) åˆå§‹åŒ– `latent = noise ~ N(0, I)`ï¼ˆshape `[16, T_lat, H_lat, W_lat]`ï¼‰
2) å¯¹æ¯ä¸ª timestep tï¼š
   - æ¨¡å‹è¾“å‡º cond/uncond çš„ v
   - CFG åˆæˆ v
   - `sample_scheduler.step(v, t, latent)` æ›´æ–° latent

åœ¨ `fm_solvers.py` ä¸­ï¼š
- `step()` é‡Œä¼šå…ˆ `convert_model_output()`ï¼Œå¯¹ dpmsolver++ æŠŠ v è½¬æˆ x0_pred
- ç„¶åè°ƒç”¨ 1/2/3 é˜¶ updateï¼ˆå¤šæ­¥æ³•ï¼‰ï¼Œåœ¨ sigma_s -> sigma_t çš„ ODE ä¸Šå‰è¿›ã€‚

ä½ å¦‚æœåªæƒ³æŠ“ä½â€œç›´è§‰â€ï¼š
- æ¨¡å‹ç»™å‡ºâ€œå¾€æ•°æ®æ–¹å‘èµ°çš„é€Ÿåº¦â€
- solver åƒé«˜é˜¶ç§¯åˆ†å™¨ï¼Œå†³å®šä½ æ¯ä¸€æ­¥èµ°å¤šè¿œã€æ€ä¹ˆç»“åˆå†å²é€Ÿåº¦ä»¥å‡å°‘è¯¯å·®ã€‚

# æ•°æ®åœ¨é‡Œé¢wanä¸­çš„ä¸€æ¬¡å®Œæ•´æµè½¬ç¤ºä¾‹


è´´è¿‘å®é™…æ¨ç†çš„è®¾ç½®ï¼š
- **å¸§æ•°**ï¼š`F = 81`ï¼ˆæ»¡è¶³ \(4n+1\)ï¼Œn=20ï¼›`image2video.py`ä¹Ÿé»˜è®¤81ï¼‰
- **åˆ†è¾¨ç‡**ï¼š`H = 720, W = 1280`ï¼ˆå…¸å‹720pï¼‰
- **VAE å‹ç¼©æ¯”**ï¼šæ—¶é—´Ã—4ï¼Œç©ºé—´Ã—8Ã—8ï¼ˆè®ºæ–‡4.1.1ï¼‰
- **DiT patch_size**ï¼š`(tP,hP,wP)=(1,2,2)`ï¼ˆ`WanModel`é»˜è®¤ï¼‰
- **latent é€šé“æ•°**ï¼š`C_lat=16`
- **Transformer éšè—ç»´**ï¼š`dim=2048`ï¼ˆ14Bé…ç½®å¸¸è§ï¼‰
- **head æ•°**ï¼š`num_heads=16` â†’ `head_dim=128`

> æ³¨ï¼š`image2video.py`é‡Œä¼šæ ¹æ® `max_area` å’Œ `vae_stride/patch_size` æŠŠè¾“å…¥å›¾ resize åˆ°èƒ½æ•´é™¤çš„ `h,w`ï¼›ä¸‹é¢æˆ‘ç›´æ¥ä»¥â€œç†æƒ³æ•´é™¤â€çš„å°ºå¯¸æ¥è®²æ¸…æ¥šæ•°æ®æµã€‚720/8=90ã€1280/8=160 æœ¬æ¥å°±èƒ½æ•´é™¤ï¼Œä¸”å†/2ä¹Ÿæ•´é™¤ï¼Œæ­£å¥½å¾ˆå¹²å‡€ã€‚


**Pixel** `[3,81,720,1280]`  
â†’ **VAE encode** `[16,21,90,160]`  
â†’ **DiT patchify** tokens `[1,75600,2048]`ï¼ˆgrid_sizes=(21,45,80)ï¼‰  
â†’ **DiT unpatchify** `[16,21,90,160]`  
â†’ **solver step** æ›´æ–° latentï¼ˆshapeä¸å˜ï¼‰  
â†’ **VAE decode** `[3,81,720,1280]`

## step1 åƒç´ åŸŸè¾“å…¥ï¼ˆPixel Videoï¼‰

åƒç´ è§†é¢‘å¼ é‡ï¼ˆå•æ ·æœ¬ï¼‰ï¼š
- **shape**ï¼š`[C, F, H, W] = [3, 81, 720, 1280]`
- ç»´åº¦è¯­ä¹‰ï¼š
  - C=3ï¼šRGBé€šé“
  - F=81ï¼šå¸§æ•°ï¼ˆæ—¶é—´ç»´ï¼‰
  - H/Wï¼šåƒç´ ç©ºé—´åˆ†è¾¨ç‡


## step2 Wan-VAE Encoderï¼šåƒç´  â†’ latent

è®ºæ–‡ç»™å‡ºï¼šè¾“å…¥ \((1+T)\) å¸§è¾“å‡º \((1+T/4)\) å¸§ latentï¼›ç©ºé—´ H/8,W/8ï¼›é€šé“ C=16ã€‚

å› æ­¤ï¼š

**latent æ—¶é—´é•¿åº¦**
\[
T_{lat} = 1 + \frac{F-1}{4} = 1 + \frac{80}{4} = 21
\]
ä»£ç å¯¹åº”ï¼š`(F-1)//4 + 1`

**latent ç©ºé—´å¤§å°**
\[
H_{lat}=720/8=90,\quad W_{lat}=1280/8=160
\]

**VAE è¾“å‡º latent**
- **shape**ï¼š`[C_lat, T_lat, H_lat, W_lat] = [16, 21, 90, 160]`

**ç»´åº¦è¯­ä¹‰**ï¼š
- 16ï¼šlatenté€šé“ï¼ˆVAEç¼–ç åç‰¹å¾é€šé“ï¼‰
- 21ï¼šlatentæ—¶é—´æ­¥ï¼ˆå¯¹åº”åƒç´ çš„ 1 + 20ç»„Ã—4å¸§ï¼‰
- 90Ã—160ï¼šlatentç©ºé—´ç½‘æ ¼ï¼ˆæ¯æ ¼å¯¹åº”åƒç´ ç©ºé—´ 8Ã—8 çš„æ„Ÿå—é‡å°ºåº¦ï¼‰

> é‡è¦ç›´è§‰ï¼šVAEä¸æ˜¯â€œé€å¸§ç‹¬ç«‹ç¼–ç â€ï¼Œå®ƒæ˜¯ 3D Causal ç»“æ„ï¼›ä½†åœ¨å°ºåº¦ä¸Šå®ƒä¿è¯äº†æ—¶é—´å‹ç¼©Ã—4ä¸ç©ºé—´Ã—8ã€‚



## step3 Flow Matching / é‡‡æ ·èµ·ç‚¹ï¼šå™ªå£° latent

æ¨ç†é‡‡æ ·ä»é«˜æ–¯å™ªå£°å¼€å§‹ï¼š

- åˆå§‹å™ªå£° `noise ~ N(0,I)`
- **shape**ï¼š`[16, 21, 90, 160]`

åœ¨ `image2video.py` é‡Œå°±æ˜¯ï¼š
```python
noise = torch.randn(16, (F-1)//4+1, lat_h, lat_w)
```

## step4 DiTï¼ˆWanModelï¼‰Patchifyï¼šlatent â†’ token åºåˆ—

### step4.1 è¾“å…¥åˆ° DiT å‰çš„ batch ç»´
`WanModel.forward()` çš„ `x` æ˜¯ listï¼Œæ¯ä¸ªæ ·æœ¬ `u` æ˜¯ `[C, T, H, W]`ï¼Œå†…éƒ¨ä¼š `u.unsqueeze(0)`ï¼š
- **è¾“å…¥åˆ° patch_embedding çš„ shape**ï¼š`[B, C_in, T_lat, H_lat, W_lat]`
- è¿™é‡Œå•æ ·æœ¬ï¼š`[1, 16, 21, 90, 160]`

### step4.2 patch_embeddingï¼ˆConv3dï¼‰è¾“å‡ºç½‘æ ¼
patch_size=(1,2,2)ï¼Œstride=(1,2,2)ï¼Œæ‰€ä»¥ï¼š
- æ—¶é—´ä¸ä¸‹é‡‡æ ·ï¼š`Fp = 21 / 1 = 21`
- ç©ºé—´å„ /2ï¼š`Hp = 90 / 2 = 45`ï¼Œ`Wp = 160 / 2 = 80`

è¾“å‡ºï¼š
- **shape**ï¼š`[1, dim, Fp, Hp, Wp] = [1, 2048, 21, 45, 80]`

### step4.3 flatten æˆ token åºåˆ—
ä»£ç ï¼š
```python
u.flatten(2).transpose(1,2)
```
- `flatten(2)`ï¼šæŠŠ `(Fp,Hp,Wp)` å±•å¹³ä¸º `L`
- `transpose`ï¼šå˜æˆ token åœ¨ä¸­é—´ç»´

æ‰€ä»¥ token åºåˆ—ï¼š
- **shape**ï¼š`[B, L, dim]`
- å…¶ä¸­ï¼š
  \[
  L = Fp \cdot Hp \cdot Wp = 21 \cdot 45 \cdot 80 = 75{,}600
  \]
- å³ **tokens shape = `[1, 75600, 2048]`**

ç»´åº¦è¯­ä¹‰ï¼š
- L=75600ï¼šæ‰€æœ‰æ—¶ç©º patch token çš„åºåˆ—é•¿åº¦ï¼ˆæ—¶ç©ºæ··åˆåºåˆ—ï¼‰
- dim=2048ï¼šæ¯ä¸ªtokençš„éšè—è¡¨ç¤º

> è¿™ä¸€æ­¥æ˜¯â€œä¸ºä»€ä¹ˆè§†é¢‘ DiT æ˜¾å­˜/ç®—åŠ›çˆ†ç‚¸â€çš„æ ¸å¿ƒï¼šself-attn çš„ç†è®ºå¤æ‚åº¦ ~ \(O(L^2)\)ã€‚

## step5 DiT Self-Attentionï¼šæ—¶ç©ºä¸€èµ·åš

ç»“è®ºï¼š**æ˜¯çš„ï¼ŒWan çš„ DiT self-attention æ²¡æœ‰æŠŠ spatial/temporal æ‹†å¼€ï¼Œè€Œæ˜¯å¯¹ (F,H,W) flatten åçš„æ‰€æœ‰ token åšä¸€æ¬¡å®Œæ•´ self-attn**ã€‚

æºç è¯æ®ï¼š
- `WanSelfAttention.forward()` æ”¶åˆ°çš„æ˜¯ `[B, L, dim]`ï¼ˆå†…éƒ¨æŠ•å½±æˆ `[B,L,heads,head_dim]`ï¼‰
- `rope_apply(q, grid_sizes=(Fp,Hp,Wp), freqs)`ï¼šç”¨ **3D RoPE** ç»™ token åŠ æ—¶ç©ºä½ç½®ä¿¡æ¯
- `flash_attention(q,k,v,k_lens=seq_lens)`ï¼šå¯¹æ•´ä¸ªåºåˆ—åš attentionï¼ˆä¸åŒºåˆ†ç©ºé—´/æ—¶é—´ï¼‰

å› æ­¤æ¯ä¸ª token éƒ½å¯ä»¥ç›´æ¥æ³¨æ„åˆ°ä»»æ„æ—¶ç©ºä½ç½®çš„ tokenï¼ˆå…¨å±€æ—¶ç©ºæ³¨æ„åŠ›ï¼‰ï¼Œå¹¶ç”¨ RoPE ç¼–ç ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚

## step6 Cross-Attentionï¼šæ–‡æœ¬/å›¾åƒæ¡ä»¶æ³¨å…¥ï¼ˆI2Væƒ…å½¢ï¼‰

ä»¥ I2V ä¸ºä¾‹ï¼ˆ`WanI2VCrossAttention`ï¼‰ï¼š
- context = `[CLIPå›¾åƒtokens ; T5æ–‡æœ¬tokens]`
- query = è§†é¢‘ tokensï¼ˆé•¿åº¦ L=75600ï¼‰
- åšä¸¤æ¬¡ cross-attnï¼šå¯¹å›¾åƒåˆ†æ”¯ã€å¯¹æ–‡æœ¬åˆ†æ”¯ï¼Œç„¶åç›¸åŠ 

è¿™è§£é‡Šäº† I2V ä¸ºä»€ä¹ˆâ€œçœ‹èµ·æ¥â€åƒåŒæ—¶ç”¨å›¾åƒå’Œæ–‡æœ¬åœ¨æ§åˆ¶è§†é¢‘ç”Ÿæˆã€‚

## step7 Head + unpatchifyï¼štoken â†’ latent é¢„æµ‹ï¼ˆæºç  `unpatchify`ï¼‰
### step7.1 Head è¾“å‡ºç»´åº¦
Head è¾“å‡ºæ¯ä¸ª token å¯¹åº”ä¸€ä¸ª patch çš„æ‰€æœ‰å…ƒç´ ï¼ˆpatchä½“ç´ æ•°Ã—out_dimï¼‰ï¼š
- `out_dim=16`
- `prod(patch_size)=1*2*2=4`
- æ‰€ä»¥æ¯ä¸ª token è¾“å‡ºç»´åº¦ï¼š`16*4=64`

Head è¾“å‡ºï¼š
- **shape**ï¼š`[B, L, 64] = [1, 75600, 64]`

### step7.2 unpatchify è¿˜åŸå› latent ç½‘æ ¼
unpatchify è¿‡ç¨‹æœ¬è´¨æ˜¯æŠŠåºåˆ— reshape æˆï¼š
- `[Fp,Hp,Wp, tP,hP,wP, C]`
å†é‡æ’å¹¶åˆå¹¶ patch ç»´ã€‚

è¿˜åŸåè¾“å‡º latentï¼š
- **shape**ï¼š`[C_out, T_lat, H_lat, W_lat] = [16, 21, 90, 160]`

è¿™ä¸è¾“å…¥ latent shape å®Œå…¨ä¸€è‡´ï¼Œæ‰€ä»¥ scheduler å¯ä»¥ç›´æ¥ç”¨å®ƒæ¥æ›´æ–° latentã€‚

## step8 Scheduler.stepï¼šç”¨ flow matching çš„ solver æ›´æ–° latent
æ¨ç†å¾ªç¯æ¯ä¸€æ­¥ï¼š
- è¾“å…¥ `sample`ï¼š`[1,16,21,90,160]`
- æ¨¡å‹è¾“å‡º `model_output`ï¼šåŒ shapeï¼ˆè¯­ä¹‰æ˜¯ flow/velocityï¼Œè™½ç„¶ä¸Šå±‚å˜é‡åå¸¸å« noise_predï¼‰

åœ¨ `FlowDPMSolverMultistepScheduler.convert_model_output()` é‡Œï¼ˆdpmsolver++ï¼‰ï¼š
\[
x_0^{pred} = x - \sigma_t \cdot v
\]
ç„¶åç”¨ä¸€é˜¶/äºŒé˜¶/ä¸‰é˜¶å¤šæ­¥æ³•ç§¯åˆ†æ›´æ–°åˆ°ä¸‹ä¸€ sigma çš„ latentã€‚

**ç»´åº¦åœ¨ scheduler å†…ä¸å˜**ï¼šä¸€ç›´ `[1,16,21,90,160]`ã€‚

## step9 Wan-VAE Decoderï¼šlatent â†’ åƒç´ è§†é¢‘
æœ€ç»ˆ latentï¼ˆå»å™ªå®Œæˆï¼‰ï¼š
- `[16,21,90,160]`

decode å›åƒç´ ï¼š
- æ—¶é—´æ¢å¤Ã—4ï¼š21 â†’ 81
- ç©ºé—´æ¢å¤Ã—8ï¼š90â†’720ï¼Œ160â†’1280
- è¾“å‡ºï¼š
  - **shape**ï¼š`[3,81,720,1280]`

# è®¾è®¡å–èˆæ€»ç»“ï¼šä¸ºä»€ä¹ˆè¿™ä¹ˆè®¾è®¡ï¼Ÿ

## VAE é€‰ 4Ã—8Ã—8ã€C=16
- å¼ºå‹ç¼©é™ä½ DiT token æ•°ï¼Œé¿å…æ³¨æ„åŠ›äºŒæ¬¡æ–¹çˆ†ç‚¸ï¼ˆè®ºæ–‡4.3.1ä¹Ÿåˆ†æ attention æ˜¯ç“¶é¢ˆï¼‰ã€‚
- C=16 åœ¨é‡å»ºè´¨é‡ä¸æ‰©æ•£éš¾åº¦ä¹‹é—´æŠ˜ä¸­ï¼ˆè®ºæ–‡å›¾7/8å¯¹æ¯”å…¶ä»–VAEï¼‰ã€‚

## CausalConv3d + cache
- è®© VAE èƒ½â€œæµå¼å¤„ç†é•¿è§†é¢‘â€ï¼Œæ˜¾å­˜ä¸éšå¸§æ•°çº¿æ€§çˆ†ç‚¸ï¼ˆè®ºæ–‡4.1.3ï¼‰ã€‚
- cache çš„æœ¬è´¨æ˜¯æŠŠå·ç§¯çš„ receptive field åœ¨ chunk è¾¹ç•Œå»¶ç»­èµ·æ¥ï¼Œä½¿ chunk-wise è¾“å‡º â‰ˆ full sequence è¾“å‡ºã€‚

## DiT ä½¿ç”¨ full spatio-temporal self-attn
- è¡¨è¾¾åŠ›å¼ºï¼šä»»æ„æ—¶ç©ºä½ç½®å¯ç›´æ¥äº¤äº’
- ä»£ä»·é«˜ï¼štoken è¶…é•¿æ—¶ attention æˆä¸»è¦ç“¶é¢ˆï¼ˆè®ºæ–‡4.3.1ç»™å‡ºå¤æ‚åº¦è¡¨è¾¾å¼ï¼Œå¹¶è¯´æ˜é•¿åºåˆ—ä¸‹ attention å æ¯”å¯åˆ°95%ï¼‰

å› æ­¤è®ºæ–‡åé¢å¤§é‡è®¨è®ºå¹¶è¡Œã€cacheã€é‡åŒ–ç­‰åŠ é€Ÿæ‰‹æ®µã€‚

## Flow Matching
- è®­ç»ƒæ›´ç¨³å®šï¼ˆè®ºæ–‡4.2.2å¼ºè°ƒ ODE/ç­‰ä»·MLï¼‰
- æ¨¡å‹ç›´æ¥å­¦ velocityï¼Œé‡‡æ ·å¯ç”¨é«˜é˜¶ ODE solverï¼ˆDPM-Solver/UniPCï¼‰


# â€œæŠ½è±¡ç‚¹â€å¿«é€Ÿå¯¹ç…§è¡¨

- **åƒç´ è§†é¢‘**ï¼š`[3, F, H, W]`
- **VAE latent**ï¼š`[16, T_lat, H/8, W/8]`ï¼Œ`T_lat = 1 + (F-1)//4`
- **DiT patchç½‘æ ¼**ï¼š`(Fp,Hp,Wp) = (T_lat/1, (H/8)/2, (W/8)/2)`ï¼ˆpatch=(1,2,2)ï¼‰
- **tokenåºåˆ—é•¿åº¦**ï¼š`L = Fp*Hp*Wp`
- **DiT tokenè¡¨ç¤º**ï¼š`[B, seq_len, dim]`
- **Self-attn**ï¼šå¯¹ token åºåˆ—åšå…¨æ³¨æ„åŠ›ï¼ˆRoPEç¼–ç F/H/Wä½ç½®ï¼‰
- **Cross-attn**ï¼šè§†é¢‘tokens(query) attend åˆ°æ¡ä»¶tokens(key/value)ï¼Œæ¡ä»¶tokensæ¥è‡ª T5/CLIP/ä½ æœªæ¥è¦åŠ çš„ref tokens
- **Flow matching**ï¼šæ¨¡å‹è¾“å‡º vï¼ˆvelocityï¼‰ï¼Œsolver å°† v è½¬æˆ x0_pred æˆ– epsilon å¹¶ç§¯åˆ†æ›´æ–° latent



